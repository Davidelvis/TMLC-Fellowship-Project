{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6f41310",
   "metadata": {},
   "source": [
    "# NLP: Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b7c6100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import re\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0e08ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define configuration file paths\n",
    "lr = 0.0001\n",
    "input_size = 50\n",
    "num_epochs = 50\n",
    "hidden_size = 50\n",
    "label_col = \"products\"\n",
    "tokens_path = \"Output/tokens.pkl\"\n",
    "labels_path = \"Output/labels.pkl\"\n",
    "data_path = \"Input/ecommerceDataset.csv\"\n",
    "rnn_model_path = \"Output/model_rnn.pth\"\n",
    "lstm_model_path = \"Output/model_lstm.pth\"\n",
    "vocabulary_path = \"Output/vocabulary.pkl\"\n",
    "embeddings_path = \"Output/embeddings.pkl\"\n",
    "glove_vector_path = \"Input/glove.6B.50d.txt\"\n",
    "text_col_name = \"product_decsription\"\n",
    "label_encoder_path = \"Output/label_encoder.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0858513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for saving a file\n",
    "def save_file(name, obj):\n",
    "    \"\"\"\n",
    "    Function to save an object as pickle file\n",
    "    \"\"\"\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "# define function for loading a file\n",
    "def load_file(name):\n",
    "    \"\"\"\n",
    "    Function to load a pickle object\n",
    "    \"\"\"\n",
    "    return pickle.load(open(name, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e2835",
   "metadata": {},
   "source": [
    "## Process glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a93de1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the glove embeddings file and read\n",
    "with open(glove_vector_path, \"rt\") as f:\n",
    "    emb = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cf2a2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of embeddings\n",
    "len(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c21095f",
   "metadata": {},
   "source": [
    "## Check the first record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d19c346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the 0.418 0.24968 -0.41242 0.1217 0.34527 -0.044457 -0.49688 -0.17862 -0.00066023 -0.6566 0.27843 -0.14767 -0.55677 0.14658 -0.0095095 0.011658 0.10204 -0.12792 -0.8443 -0.12181 -0.016801 -0.33279 -0.1552 -0.23131 -0.19181 -1.8823 -0.76746 0.099051 -0.42125 -0.19526 4.0071 -0.18594 -0.52287 -0.31681 0.00059213 0.0074449 0.17778 -0.15897 0.012041 -0.054223 -0.29871 -0.15749 -0.34758 -0.045637 -0.44251 0.18785 0.0027849 -0.18411 -0.11514 -0.78581\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check first record\n",
    "emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d02fa70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the first record and check for vocabulary\n",
    "emb[0].split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf873037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.418',\n",
       " '0.24968',\n",
       " '-0.41242',\n",
       " '0.1217',\n",
       " '0.34527',\n",
       " '-0.044457',\n",
       " '-0.49688',\n",
       " '-0.17862',\n",
       " '-0.00066023',\n",
       " '-0.6566',\n",
       " '0.27843',\n",
       " '-0.14767',\n",
       " '-0.55677',\n",
       " '0.14658',\n",
       " '-0.0095095',\n",
       " '0.011658',\n",
       " '0.10204',\n",
       " '-0.12792',\n",
       " '-0.8443',\n",
       " '-0.12181',\n",
       " '-0.016801',\n",
       " '-0.33279',\n",
       " '-0.1552',\n",
       " '-0.23131',\n",
       " '-0.19181',\n",
       " '-1.8823',\n",
       " '-0.76746',\n",
       " '0.099051',\n",
       " '-0.42125',\n",
       " '-0.19526',\n",
       " '4.0071',\n",
       " '-0.18594',\n",
       " '-0.52287',\n",
       " '-0.31681',\n",
       " '0.00059213',\n",
       " '0.0074449',\n",
       " '0.17778',\n",
       " '-0.15897',\n",
       " '0.012041',\n",
       " '-0.054223',\n",
       " '-0.29871',\n",
       " '-0.15749',\n",
       " '-0.34758',\n",
       " '-0.045637',\n",
       " '-0.44251',\n",
       " '0.18785',\n",
       " '0.0027849',\n",
       " '-0.18411',\n",
       " '-0.11514',\n",
       " '-0.78581']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the first record and check for embeddings\n",
    "emb[0].split()[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ed59b1",
   "metadata": {},
   "source": [
    "## Separate embeddings and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "821685bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary, embeddings = [], []\n",
    "\n",
    "for item in emb:\n",
    "    vocabulary.append(item.split()[0])\n",
    "    embeddings.append(item.split()[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94a8557",
   "metadata": {},
   "source": [
    "### Convert embeddings to numpy float array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "004674f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array(embeddings, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6432bee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 50)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2bd7d2",
   "metadata": {},
   "source": [
    "### Add embeddings for padding and unknown items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33189d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', ',', '.', 'of', 'to', 'and', 'in', 'a', '\"', \"'s\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "968143e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = [\"<pad>\", \"<unk>\"] + vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cce4719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.vstack([np.ones(50, dtype=np.float32), np.mean(embeddings, axis=0),\n",
    "                            embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b50b768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400002 (400002, 50)\n"
     ]
    }
   ],
   "source": [
    "print(len(vocabulary), embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e2450",
   "metadata": {},
   "source": [
    "### Save embeddings and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaebd142",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(embeddings_path, embeddings)\n",
    "save_file(vocabulary_path, vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74798e10",
   "metadata": {},
   "source": [
    "## Process text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c52b31",
   "metadata": {},
   "source": [
    "### Read the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3a56001",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "130ba3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_axis(['products','product_decsription'], axis=\"columns\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ee7b755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>products</th>\n",
       "      <th>product_decsription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Household</td>\n",
       "      <td>Paper Plane Design Framed Wall Hanging Motivat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'Floral' Framed Painting (Wood, 30 inch x ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'UV Textured Modern Art Print Framed' Pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF Flower Print Framed Painting (Synthetic, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Household</td>\n",
       "      <td>Incredible Gifts India Wooden Happy Birthday U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50420</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Strontium MicroSD Class 10 8GB Memory Card (Bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50421</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>CrossBeats Wave Waterproof Bluetooth Wireless ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50422</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Karbonn Titanium Wind W4 (White) Karbonn Titan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50423</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Samsung Guru FM Plus (SM-B110E/D, Black) Colou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50424</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Micromax Canvas Win W121 (White)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50425 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          products                                product_decsription\n",
       "0        Household  Paper Plane Design Framed Wall Hanging Motivat...\n",
       "1        Household  SAF 'Floral' Framed Painting (Wood, 30 inch x ...\n",
       "2        Household  SAF 'UV Textured Modern Art Print Framed' Pain...\n",
       "3        Household  SAF Flower Print Framed Painting (Synthetic, 1...\n",
       "4        Household  Incredible Gifts India Wooden Happy Birthday U...\n",
       "...            ...                                                ...\n",
       "50420  Electronics  Strontium MicroSD Class 10 8GB Memory Card (Bl...\n",
       "50421  Electronics  CrossBeats Wave Waterproof Bluetooth Wireless ...\n",
       "50422  Electronics  Karbonn Titanium Wind W4 (White) Karbonn Titan...\n",
       "50423  Electronics  Samsung Guru FM Plus (SM-B110E/D, Black) Colou...\n",
       "50424  Electronics                   Micromax Canvas Win W121 (White)\n",
       "\n",
       "[50425 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c4ba98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Household                 19313\n",
       "Books                     11820\n",
       "Electronics               10621\n",
       "Clothing & Accessories     8671\n",
       "Name: products, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.products.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11c0deb",
   "metadata": {},
   "source": [
    "### Drop rows where the text column is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a7fdeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=[text_col_name], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a232f935",
   "metadata": {},
   "source": [
    "### Encode the label column and save the encoder and encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6db032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(data[label_col])\n",
    "labels = label_encoder.transform(data[label_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ef94b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "876ed081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Books', 'Clothing & Accessories', 'Electronics', 'Household'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9734cc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Household\n",
       "1          Household\n",
       "2          Household\n",
       "3          Household\n",
       "4          Household\n",
       "            ...     \n",
       "50420    Electronics\n",
       "50421    Electronics\n",
       "50422    Electronics\n",
       "50423    Electronics\n",
       "50424    Electronics\n",
       "Name: products, Length: 50424, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[label_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c726694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(labels_path, labels)\n",
    "save_file(label_encoder_path, label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0448fdf",
   "metadata": {},
   "source": [
    "### Process the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04f795be",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = data[text_col_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da70ca1",
   "metadata": {},
   "source": [
    "### Convert text to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0adec0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 50424/50424 [00:00<00:00, 213242.39it/s]\n"
     ]
    }
   ],
   "source": [
    "input_text = [i.lower() for i in tqdm(input_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1574faf0",
   "metadata": {},
   "source": [
    "### Remove punctuations except apostrophe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5396586a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 50424/50424 [00:01<00:00, 39648.23it/s]\n"
     ]
    }
   ],
   "source": [
    "input_text = [re.sub(r\"[^\\w\\d'\\s]+\", \" \", i) for i in tqdm(input_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eadd38e",
   "metadata": {},
   "source": [
    "### Remove digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "944bde63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 50424/50424 [00:00<00:00, 73058.11it/s]\n"
     ]
    }
   ],
   "source": [
    "input_text = [re.sub(\"\\d+\", \"\", i) for i in tqdm(input_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183b9567",
   "metadata": {},
   "source": [
    "### Remove more than one consecutive instance of 'x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2a7f494",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 50424/50424 [00:00<00:00, 113562.20it/s]\n"
     ]
    }
   ],
   "source": [
    "input_text = [re.sub(r'[x]{2,}', \"\", i) for i in tqdm(input_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc128e77",
   "metadata": {},
   "source": [
    "### Replace multiple spaces with single space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b916247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 50424/50424 [00:01<00:00, 31445.91it/s]\n"
     ]
    }
   ],
   "source": [
    "input_text = [re.sub(' +', ' ', i) for i in tqdm(input_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8259eb2c",
   "metadata": {},
   "source": [
    "### Tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee4ee100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 50424/50424 [00:21<00:00, 2368.00it/s]\n"
     ]
    }
   ],
   "source": [
    "tokens = [word_tokenize(t) for t in tqdm(input_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0511bb1",
   "metadata": {},
   "source": [
    "### Take the first 20 tokens in each complaint text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4c268ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 50424/50424 [00:00<00:00, 611383.89it/s]\n"
     ]
    }
   ],
   "source": [
    "tokens = [i[:20] if len(i) > 19 else ['<pad>'] * (20 - len(i)) + i for i in tqdm(tokens)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2076d1",
   "metadata": {},
   "source": [
    "### Convert tokens to integer indices from vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6d6cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_index(tokens, vocabulary, missing='<unk>'):\n",
    "    \"\"\"\n",
    "    :param tokens: List of word tokens\n",
    "    :param vocabulary: All words in the embeddings\n",
    "    :param missing: Token for words not present in the vocabulary\n",
    "    :return: List of integers representing the word tokens\n",
    "    \"\"\"\n",
    "    idx_token = []\n",
    "    for text in tqdm(tokens):\n",
    "        idx_text = []\n",
    "        for token in text:\n",
    "            if token in vocabulary:\n",
    "                idx_text.append(vocabulary.index(token))\n",
    "            else:\n",
    "                idx_text.append(vocabulary.index(missing))\n",
    "        idx_token.append(idx_text)\n",
    "    return idx_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40d4b504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 50424/50424 [28:19<00:00, 29.67it/s]\n"
     ]
    }
   ],
   "source": [
    "tokens = token_index(tokens, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a45add22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50424"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ff8838f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1309,\n",
       " 1315,\n",
       " 1254,\n",
       " 11878,\n",
       " 1017,\n",
       " 5664,\n",
       " 25892,\n",
       " 285,\n",
       " 22359,\n",
       " 762,\n",
       " 10472,\n",
       " 1587,\n",
       " 6523,\n",
       " 210,\n",
       " 5,\n",
       " 3714,\n",
       " 118,\n",
       " 62,\n",
       " 8,\n",
       " 11862]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "eb4b6096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>products</th>\n",
       "      <th>product_decsription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Household</td>\n",
       "      <td>Paper Plane Design Framed Wall Hanging Motivat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'Floral' Framed Painting (Wood, 30 inch x ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'UV Textured Modern Art Print Framed' Pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF Flower Print Framed Painting (Synthetic, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Household</td>\n",
       "      <td>Incredible Gifts India Wooden Happy Birthday U...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    products                                product_decsription\n",
       "0  Household  Paper Plane Design Framed Wall Hanging Motivat...\n",
       "1  Household  SAF 'Floral' Framed Painting (Wood, 30 inch x ...\n",
       "2  Household  SAF 'UV Textured Modern Art Print Framed' Pain...\n",
       "3  Household  SAF Flower Print Framed Painting (Synthetic, 1...\n",
       "4  Household  Incredible Gifts India Wooden Happy Birthday U..."
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89728214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paper'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[tokens[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5902fadd",
   "metadata": {},
   "source": [
    "### Save the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e73d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(tokens_path, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71349b7e",
   "metadata": {},
   "source": [
    "## Create PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf81125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, tokens, embeddings, labels):\n",
    "        \"\"\"\n",
    "        :param tokens: List of word tokens\n",
    "        :param embeddings: Word embeddings (from glove)\n",
    "        :param labels: List of labels\n",
    "        \"\"\"\n",
    "        self.tokens = tokens\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.labels[idx], self.embeddings[self.tokens[idx], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6368e71",
   "metadata": {},
   "source": [
    "## Create Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd17e00f",
   "metadata": {},
   "source": [
    "### RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "220cff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNNetwork(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        \"\"\"\n",
    "        :param input_size: Size of embedding\n",
    "        :param hidden_size: Hidden vector size\n",
    "        :param num_classes: Number of classes in the dataset\n",
    "        \"\"\"\n",
    "        super(RNNNetwork, self).__init__()\n",
    "        # RNN Layer\n",
    "        self.rnn = torch.nn.RNN(input_size=input_size,\n",
    "                                hidden_size=hidden_size,\n",
    "                                batch_first=True)\n",
    "        # Linear Layer\n",
    "        self.linear = torch.nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        _, hidden = self.rnn(input_data)\n",
    "        output = self.linear(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05de12c",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b895f515",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNetwork(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        \"\"\"\n",
    "        :param input_size: Size of embedding\n",
    "        :param hidden_size: Hidden vector size\n",
    "        :param num_classes: Number of classes in the dataset\n",
    "        \"\"\"\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "        # LSTM Layer\n",
    "        self.rnn = torch.nn.LSTM(input_size=input_size,\n",
    "                                 hidden_size=hidden_size,\n",
    "                                 batch_first=True)\n",
    "        # Linear Layer\n",
    "        self.linear = torch.nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        _, (hidden, _) = self.rnn(input_data)\n",
    "        output = self.linear(hidden[-1])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8723b4",
   "metadata": {},
   "source": [
    "### Define train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b0f025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, valid_loader, model, criterion, optimizer, device,\n",
    "          num_epochs, model_path):\n",
    "    \"\"\"\n",
    "    Function to train the model\n",
    "    :param train_loader: Data loader for train dataset\n",
    "    :param valid_loader: Data loader for validation dataset\n",
    "    :param model: Model object\n",
    "    :param criterion: Loss function\n",
    "    :param optimizer: Optimizer\n",
    "    :param device: CUDA or CPU\n",
    "    :param num_epochs: Number of epochs\n",
    "    :param model_path: Path to save the model\n",
    "    \"\"\"\n",
    "    best_loss = 1e8\n",
    "    for i in range(num_epochs):\n",
    "        print(f\"Epoch {i+1} of {num_epochs}\")\n",
    "        valid_loss, train_loss = [], []\n",
    "        model.train()\n",
    "        # Train loop\n",
    "        for batch_labels, batch_data in tqdm(train_loader):\n",
    "            # Move data to GPU if available\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            batch_labels = batch_labels.type(torch.LongTensor)\n",
    "            batch_data = batch_data.to(device)\n",
    "            # Forward pass\n",
    "            batch_output = model(batch_data)\n",
    "            batch_output = torch.squeeze(batch_output)\n",
    "            # Calculate loss\n",
    "            loss = criterion(batch_output, batch_labels)\n",
    "            train_loss.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            # Gradient update step\n",
    "            optimizer.step()\n",
    "        model.eval()\n",
    "        # Validation loop\n",
    "        for batch_labels, batch_data in tqdm(valid_loader):\n",
    "            # Move data to GPU if available\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            batch_labels = batch_labels.type(torch.LongTensor)\n",
    "            batch_data = batch_data.to(device)\n",
    "            # Forward pass\n",
    "            batch_output = model(batch_data)\n",
    "            batch_output = torch.squeeze(batch_output)\n",
    "            # Calculate loss\n",
    "            loss = criterion(batch_output, batch_labels)\n",
    "            valid_loss.append(loss.item())\n",
    "        t_loss = np.mean(train_loss)\n",
    "        v_loss = np.mean(valid_loss)\n",
    "        print(f\"Train Loss: {t_loss}, Validation Loss: {v_loss}\")\n",
    "        if v_loss < best_loss:\n",
    "            best_loss = v_loss\n",
    "            # Save model if validation loss improves\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        print(f\"Best Validation Loss: {best_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a75b017",
   "metadata": {},
   "source": [
    "### Define test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "492ad55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, criterion, device):\n",
    "    \"\"\"\n",
    "    Function to test the model\n",
    "    :param test_loader: Data loader for test dataset\n",
    "    :param model: Model object\n",
    "    :param criterion: Loss function\n",
    "    :param device: CUDA or CPU\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    test_accu = []\n",
    "    for batch_labels, batch_data in tqdm(test_loader):\n",
    "        # Move data to device\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        batch_labels = batch_labels.type(torch.LongTensor)\n",
    "        batch_data = batch_data.to(device)\n",
    "        # Forward pass\n",
    "        batch_output = model(batch_data)\n",
    "        batch_output = torch.squeeze(batch_output)\n",
    "        # Calculate loss\n",
    "        loss = criterion(batch_output, batch_labels)\n",
    "        test_loss.append(loss.item())\n",
    "        batch_preds = torch.argmax(batch_output, axis=1)\n",
    "        # Move predictions to CPU\n",
    "        if torch.cuda.is_available():\n",
    "            batch_labels = batch_labels.cpu()\n",
    "            batch_preds = batch_preds.cpu()\n",
    "        # Compute accuracy\n",
    "        test_accu.append(accuracy_score(batch_labels.detach().numpy(),\n",
    "                                        batch_preds.detach().numpy()))\n",
    "    test_loss = np.mean(test_loss)\n",
    "    test_accu = np.mean(test_accu)\n",
    "    print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accu}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de78ee66",
   "metadata": {},
   "source": [
    "### Train RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5da6da5",
   "metadata": {},
   "source": [
    "### Load the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9f681e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = load_file(tokens_path)\n",
    "labels = load_file(labels_path)\n",
    "embeddings = load_file(embeddings_path)\n",
    "label_encoder = load_file(label_encoder_path)\n",
    "num_classes = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac6e48",
   "metadata": {},
   "source": [
    "### Split data into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "abc99b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tokens, labels,\n",
    "                                                    test_size=0.2)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train,\n",
    "                                                      test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c699574",
   "metadata": {},
   "source": [
    "### Create PyTorch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e18930cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(X_train, embeddings, y_train)\n",
    "valid_dataset = TextDataset(X_valid, embeddings, y_valid)\n",
    "test_dataset = TextDataset(X_test, embeddings, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350558eb",
   "metadata": {},
   "source": [
    "### Create data loaders¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c24e129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16,\n",
    "                                           shuffle=True, drop_last=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=16)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f070a1a1",
   "metadata": {},
   "source": [
    "### Create model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d9db3278",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNNetwork(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6ae620",
   "metadata": {},
   "source": [
    "### Move the model to GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e250099",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e0efce",
   "metadata": {},
   "source": [
    "### Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "703e5fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNNetwork(\n",
       "  (rnn): RNN(50, 50, batch_first=True)\n",
       "  (linear): Linear(in_features=50, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3523f6c",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dd00d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_loader, valid_loader, model, criterion, optimizer,\n",
    "      device, num_epochs, rnn_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314a42e4",
   "metadata": {},
   "source": [
    "### Train LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "75c5973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMNetwork(input_size, hidden_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3a981051",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b4cc4589",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "beb5943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_loader, valid_loader, model, criterion, optimizer,\n",
    "      device, num_epochs, lstm_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e36fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(test_loader, model, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758eb230",
   "metadata": {},
   "source": [
    "### Predict on new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a85713d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = '''ART DIOR | Dancing Village Girls \n",
    "| Canvas Wall Art | Unframed Canvas Art Print | 18 inch x 46 inch |'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cbdf81",
   "metadata": {},
   "source": [
    "### Process input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "856555ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = input_text.lower()\n",
    "input_text = re.sub(r\"[^\\w\\d'\\s]+\", \" \", input_text)\n",
    "input_text = re.sub(\"\\d+\", \"\", input_text)\n",
    "input_text = re.sub(r'[x]{2,}', \"\", input_text)\n",
    "input_text = re.sub(' +', ' ', input_text)\n",
    "tokens = word_tokenize(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcf0991",
   "metadata": {},
   "source": [
    "### Add padding if the length of tokens is less than 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f3ba7937",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['<pad>']*(20-len(tokens))+tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c093aee",
   "metadata": {},
   "source": [
    "### Tokenize the input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "195c5b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_token = []\n",
    "for token in tokens:\n",
    "    if token in vocabulary:\n",
    "        idx_token.append(vocabulary.index(token))\n",
    "    else:\n",
    "        idx_token.append(vocabulary.index('<unk>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc8fb92",
   "metadata": {},
   "source": [
    "### Get embeddings for tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "12cb7b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_emb = embeddings[idx_token,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42705153",
   "metadata": {},
   "source": [
    "### Convert to torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ca3a7a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.from_numpy(token_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaf7fac",
   "metadata": {},
   "source": [
    "### Move the tensor to GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "199e7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = inp.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c77f99",
   "metadata": {},
   "source": [
    "### Create a batch of one record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dde5cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.unsqueeze(inp, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10da399f",
   "metadata": {},
   "source": [
    "### Load label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "404c6255",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = load_file(label_encoder_path)\n",
    "num_classes = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1c7b24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40bde85",
   "metadata": {},
   "source": [
    "### RNN prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "326d129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object\n",
    "model = RNNNetwork(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Load trained weights\n",
    "model.load_state_dict(torch.load(rnn_model_path))\n",
    "\n",
    "# Move the model to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    \n",
    "# Forward pass\n",
    "out = torch.squeeze(model(inp))\n",
    "\n",
    "# Find predicted class\n",
    "prediction = label_encoder.classes_[torch.argmax(out)]\n",
    "print(f\"Predicted  Class: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab1349e",
   "metadata": {},
   "source": [
    "### LSTM prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fcb57116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object\n",
    "model = LSTMNetwork(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Load trained weights\n",
    "model.load_state_dict(torch.load(lstm_model_path))\n",
    "\n",
    "# Move the model to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    \n",
    "# Forward pass\n",
    "out = torch.squeeze(model(inp))\n",
    "\n",
    "# Find predicted class\n",
    "prediction = label_encoder.classes_[torch.argmax(out)]\n",
    "print(f\"Predicted  Class: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeea92d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
